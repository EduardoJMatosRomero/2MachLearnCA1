{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "029e294b",
   "metadata": {},
   "source": [
    "In the retail sector, it is possible to unlock insights to win and retain customers, drive business efficiencies, and ultimately improve sales and customer interest. Retail organizations are using advanced analysis to understand their customers, improve forecasting, and achieve better, faster results. As a company's resources are limited, it is crucial to identify and target customers to secure their loyalty, enhance business efficiency, and ultimately improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a909c930",
   "metadata": {},
   "source": [
    "You have been given access to a dataset containing customer transactions for an online retailer and tasked with using your machine learning tools to gain and report on business insights. The audience for this report are non-specialists.  In particular, your tasks are:\n",
    "\n",
    "Clustering\n",
    "Apply and evaluate various clustering techniques with the aim of generating actionable insights from the data. \n",
    "\n",
    "●\tSelect and justify the features you will be using.\n",
    "\n",
    "●\tApply appropriate clustering algorithms to the dataset.\n",
    "\n",
    "●\tEvaluate the performance of the algorithms and make a recommendation as to which gives the “best” results.\n",
    "\n",
    "●\tInclude in your report your own interpretation of the results.\n",
    "\n",
    "Market Basket Analysis\n",
    "Perform a market basket analysis of the transaction data. \n",
    "\n",
    "●\tInclude in your report a comparison and evaluation of at least two algorithms.\n",
    "\n",
    "●\tInclude in your report your own interpretation of the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e205d3b",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The analysis focuses on clustering regularly purchased products to identify patterns and gain insights into consumer buying behaviour. This approach facilitates a better understanding of the dynamics of everyday purchases, enabling more targeted marketing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06c9a74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.12.2-py3-none-any.whl (257 kB)\n",
      "Collecting scikit-learn>=1.0.2\n",
      "  Using cached scikit_learn-1.4.2-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.7.1)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.4.0-py3-none-any.whl (301 kB)\n",
      "Installing collected packages: joblib, scikit-learn, imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.12.2 joblib-1.4.0 scikit-learn-1.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imblearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14460/3531296096.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install imbalanced-learn --user'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imblearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "!pip install imbalanced-learn --user\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0699741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c1850",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "To improve readability, we have set the 'InvoiceDate' column as the index of the dataset.\n",
    "This guarantees that each row is unique, eliminating the need for the default numerical index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad17169",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7006bd",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "An analysis using the .describe() method reveals several noteworthy observations: \n",
    "\n",
    "- The majority of transactions involve quantities ranging from 3 to 10 items, with most items priced at £5 or less. \n",
    "\n",
    "- Negative quantities and prices are present, and some records lack CustomerID data. The majority of transactions involve quantities ranging from 3 to 10 items, with most items priced at £5 or less. \n",
    "\n",
    "- The majority of transactions involve quantities ranging from 3 to 10 items, with most items priced at £5 or less. Additionally, there are several significant outliers that require further attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3daf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df = df.set_index('InvoiceDate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cdd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705bed2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a405d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5569eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_camel_case(s):\n",
    "    # Split the string into words\n",
    "    words = s.replace('_', ' ').split()\n",
    "    # Convert the first word to lowercase and capitalize the initials of the remaining words\n",
    "    camel_case_str = words[0].lower() + ''.join(word.capitalize() for word in words[1:])\n",
    "    return camel_case_str\n",
    "\n",
    "df.columns = [to_camel_case(col) for col in df.columns]\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To prevent errors, converting 'Description','Invoice' and 'StockCode' to a string.\n",
    "# df['Description'] = df['Description'].astype(str)\n",
    "# df['Invoice'] = df['Invoice'].astype(str)\n",
    "# df['StockCode'] = df['StockCode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160815cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda51f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_country=df[['country','customerId']]\n",
    "customer_country.groupby(['country'])['customerId'].aggregate('count').reset_index().sort_values('customerId', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4fc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    # Checking if any value in the column is duplicated\n",
    "    has_duplicates = df[column].duplicated().any()\n",
    "    print(f'{column} has duplicates: {has_duplicates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7d73e",
   "metadata": {},
   "source": [
    "## Null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df42018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['description'].isnull()].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c90a0",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "- The Price in these rows is 0, indicating that these orders did not generate any sales.\n",
    "\n",
    "- At present, we can impute it with 'UNKNOWN ITEM' and address those later during the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36665c2",
   "metadata": {},
   "source": [
    "## Features analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00809e78",
   "metadata": {},
   "source": [
    "#### Analyzing \"Description\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].value_counts().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd7c95",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "The code above shows that valid items are typically in uppercase, while non-valid or cancelled items are in lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4715936",
   "metadata": {},
   "source": [
    "#### Analyzing Invoice feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invoice'].value_counts().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invoice'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08316253",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b64c01",
   "metadata": {},
   "source": [
    "## Removing duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48619cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_country=df[['country','customerId','invoice']].drop_duplicates()\n",
    "customer_country.groupby(['country'])['customerId'].aggregate('count').reset_index().sort_values('customerId', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdaabaa",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "We will no longer track clients that appear to be duplicated, particularly when invoices for these customers are repeated in the same country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d27c72",
   "metadata": {},
   "source": [
    "## Labelling unknown items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7fd2bb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14460/480795850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'UNKNOWN ITEM'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['description'] = df['description'].fillna('UNKNOWN ITEM')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].fillna('UNKNOWN ITEM')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb18c595",
   "metadata": {},
   "source": [
    "## Removing unidentified customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['customerId'])]\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2bcfd7",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.scatter(x=df.index, y=df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76417f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=df.quantile(.25)\n",
    "Q3=df.quantile(.75)\n",
    "IQR=Q3-Q1\n",
    "print(IQR)\n",
    "print(\"--------\")\n",
    "print(Q1)\n",
    "print(\"--------\")\n",
    "print(Q3)\n",
    "\n",
    "df=df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33862b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_price = Q1['price'] \n",
    "\n",
    "# Filtering the dataset for products over 1.25 euros\n",
    "high_value_purchases = df[df['price'] > Q1_price]\n",
    "\n",
    "# Getting unique customers who have made high-value purchases\n",
    "unique_customers_high_value = high_value_purchases['customerId'].unique()\n",
    "\n",
    "# Getting the total number of unique customers in the entire dataset\n",
    "total_unique_customers = df['customerId'].unique()\n",
    "\n",
    "# Calculating the percentage of customers who have purchased items over 3000 euros\n",
    "percentage_high_value_customers = (len(unique_customers_high_value) / len(total_unique_customers)) * 100\n",
    "\n",
    "# Displaying the percentage\n",
    "print(f'Percentage of customers who have purchased items over 1.25 euros: {percentage_high_value_customers:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a683ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3_price = Q3['price'] \n",
    "\n",
    "# Filtering the dataset for products over 2.55 euros\n",
    "high_value_purchases = df[df['price'] > Q3_price]\n",
    "\n",
    "# Getting unique customers who have made high-value purchases\n",
    "unique_customers_high_value = high_value_purchases['customerId'].unique()\n",
    "\n",
    "# Getting the total number of unique customers in the entire dataset\n",
    "total_unique_customers = df['customerId'].unique()\n",
    "\n",
    "# Calculating the percentage of customers who have purchased items over 3000 euros\n",
    "percentage_high_value_customers = (len(unique_customers_high_value) / len(total_unique_customers)) * 100\n",
    "\n",
    "# Displaying the percentage\n",
    "print(f'Percentage of customers who have purchased items over 2.55 euros: {percentage_high_value_customers:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddce8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.scatter(x=df.index, y=df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b107bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62329b53",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "- To achieve a more precise clustering of products, we excluded products that cost over 7.5 € from our datasets. Our analysis aims to cluster regularly purchased products, and those over this price point are not considered in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e6661",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54644a",
   "metadata": {},
   "source": [
    "## Do we have returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9da31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['quantity'] < 0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3355a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['invoice'].isna().sum())\n",
    "#The code is not working unless we instruct .str.startswith() to consider NA/NaN values as False\n",
    "print(df[df['invoice'].str.startswith('C', na=False)].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef835fb9",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "Invoices beginning with the letter 'C' are designated as 'Canceling' or 'Returning' invoices.\n",
    "\n",
    "While a more in-depth analysis of these returns would be beneficial, for the sake of simplicity we will disregard them for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc03df9c",
   "metadata": {},
   "source": [
    "## How many customers are not recurrent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_counts(df):\n",
    "   for i in df.columns:\n",
    "       count = df[i].nunique()\n",
    "       print(i, \": \", count)\n",
    "unique_counts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637308f2",
   "metadata": {},
   "source": [
    "## What items were purchased more frequently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ba2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = df['description'].value_counts().sort_values(ascending=False).iloc[0:15]\n",
    "plt.figure(figsize=(18,6))\n",
    "sns.barplot(x=item_counts.index, y=item_counts.values, palette=sns.cubehelix_palette(15))\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Which items were bought more often?\");\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb5abe",
   "metadata": {},
   "source": [
    "##  Which invoices had the highest number of items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_counts = df['invoice'].value_counts().sort_values(ascending=False).iloc[0:15]\n",
    "plt.figure(figsize=(18,6))\n",
    "sns.barplot(x=inv_counts.index, y=inv_counts.values, palette=sns.color_palette(\"BuGn_d\"))\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Which invoices had the most items?\");\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a92b5",
   "metadata": {},
   "source": [
    "## What is the country with the highest number of sales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame(data = df.groupby(['country'])['invoice'].nunique(), index=df.groupby(['country']).groups.keys()).T\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42af0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.bar(list(df.groupby(['country']).groups.keys()), df.groupby(['country'])['customerId'].count())\n",
    "plt.xticks(rotation = 90, fontsize = 14)\n",
    "plt.title(\"Number of transanctions done for each country\")\n",
    "plt.ylabel(\"No. of trans.\")\n",
    "plt.xlabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the number of unique invoices per country\n",
    "sales_per_country = df.groupby('country')['invoice'].nunique()\n",
    "\n",
    "# Calculating the total number of sales transactions\n",
    "total_sales = sales_per_country.sum()\n",
    "\n",
    "# Calculating the percentage of total sales for each country\n",
    "percent_sales = (sales_per_country / total_sales) * 100\n",
    "\n",
    "# Sorting the percentages to find the countries with the smallest percent of sales\n",
    "smallest_percent_sales = percent_sales.sort_values()\n",
    "\n",
    "# Displaying the sorted percentages\n",
    "print(smallest_percent_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for countries with 1% or less in sales\n",
    "countries_with_one_percent_or_less = percent_sales[percent_sales <= 1]\n",
    "\n",
    "# Counting the number of countries meeting the criterion\n",
    "number_of_countries = countries_with_one_percent_or_less.count()\n",
    "\n",
    "# Display the count\n",
    "print(f'Number of countries with 1% or less in sales: {number_of_countries}')\n",
    "\n",
    "# Displaying the names of these countries\n",
    "print(\"Countries with 1% or less in sales:\")\n",
    "print(countries_with_one_percent_or_less.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb80f4",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "- The UK conducted the majority of the transactions, with a total of 19857.\n",
    "\n",
    "- 'Australia', 'Austria', 'Bahrain', 'Belgium', 'Brazil', 'Canada', 'Channel Islands', 'Cyprus', 'Denmark', 'Finland', 'Greece', 'Iceland', 'Israel', 'Italy', 'Japan', 'Korea', 'Lithuania', 'Malta', 'Netherlands', 'Nigeria', 'Norway', 'Poland', 'Portugal', 'RSA', 'Singapore', 'Spain', 'Sweden', 'Switzerland', 'Thailand', 'USA', 'United Arab Emirates', 'Unspecified', 'West Indies' are countries with less than the 1% of sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fd94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.groupby('invoice')[['quantity']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3167e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298295d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InvoiceDate'] = df.index\n",
    "\n",
    "# Merging df with df2 based on the invoice column using the 'left' join to retain all records from 'df' in the merged \n",
    "# DataFrame, while only the matching entries from 'df2' are included.\n",
    "\n",
    "df = df.merge(df2, how='left', on='invoice')\n",
    "\n",
    "# Changing the column names to clarify their meaning. 'quantity_x' has been replaced with 'product units' and 'quantityInv' with 'number of products invoiced in each invoice'.\n",
    "\n",
    "df = df.rename(columns={'quantity_x' : 'quantity', 'quantity_y' : 'quantityInv'})\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InvoiceDate'] = df['InvoiceDate'].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f82000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c808597",
   "metadata": {},
   "source": [
    "# Machine Learning algorithms - Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19623b65",
   "metadata": {},
   "source": [
    "To conduct a comprehensive market analysis, we will predict the frequency of product purchases. This approach is valuable despite potentially overlooking other factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292af719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for model training\n",
    "X = df.drop('quantity', axis=1)  # Assuming 'quantity' is the target variable\n",
    "y = df['quantity']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Handling imbalanced data\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initializing and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac9eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('quantity', axis=1)  # Assuming 'quantity' is the target variable\n",
    "y = df['quantity']\n",
    "\n",
    "# Splitting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Handling imbalanced data\n",
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Initializing and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
