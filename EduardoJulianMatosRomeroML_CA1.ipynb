{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "029e294b",
   "metadata": {},
   "source": [
    "In the retail sector, it is possible to unlock insights to win and retain customers, drive business efficiencies, and ultimately improve purchases and customer interest. Retail organizations are using advanced analysis to understand their customers, improve forecasting, and achieve better, faster results. As a company's resources are limited, it is crucial to identify and target customers to secure their loyalty, enhance business efficiency, and ultimately improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a909c930",
   "metadata": {},
   "source": [
    "You have been given access to a dataset containing customer transactions for an online retailer and tasked with using your machine learning tools to gain and report on business insights. The audience for this report are non-specialists.  In particular, your tasks are:\n",
    "\n",
    "Clustering\n",
    "Apply and evaluate various clustering techniques with the aim of generating actionable insights from the data. \n",
    "\n",
    "●\tSelect and justify the features you will be using.\n",
    "\n",
    "●\tApply appropriate clustering algorithms to the dataset.\n",
    "\n",
    "●\tEvaluate the performance of the algorithms and make a recommendation as to which gives the “best” results.\n",
    "\n",
    "●\tInclude in your report your own interpretation of the results.\n",
    "\n",
    "Market Basket Analysis\n",
    "Perform a market basket analysis of the transaction data. \n",
    "\n",
    "●\tInclude in your report a comparison and evaluation of at least two algorithms.\n",
    "\n",
    "●\tInclude in your report your own interpretation of the results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e205d3b",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The analysis focuses on clustering regularly purchased products to identify patterns and gain insights into consumer buying behaviour. This approach facilitates a better understanding of the dynamics of everyday purchases, enabling more targeted marketing strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c9a74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0699741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"data.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d49588",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "\n",
    "# Display the DataFrame with new columns\n",
    "print(df[['InvoiceDate', 'Year', 'Month']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f28dbd",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "It was decided to split 'InvoiceDate' into 'Year', 'Month', from the beginning to make future analysis easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a473b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "df = df.set_index('InvoiceDate')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6c1850",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "To improve readability, we have set the 'InvoiceDate' column as the index of the dataset.\n",
    "This guarantees that each row is unique, eliminating the need for the default numerical index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad17169",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7006bd",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "An analysis using the .describe() method reveals several noteworthy observations: \n",
    "\n",
    "- The majority of transactions involve quantities ranging from 3 to 10 items, with most items priced at £5 or less. \n",
    "\n",
    "- Negative quantities and prices are present, and some records lack CustomerID data. The majority of transactions involve quantities ranging from 3 to 10 items, with most items priced at £5 or less. \n",
    "\n",
    "- The majority of transactions involve quantities ranging from 3 to 10 items, with most items priced at £5 or less. Additionally, there are several significant outliers that require further attention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cdd4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705bed2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a405d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5569eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_camel_case(s):\n",
    "    # Split the string into words\n",
    "    words = s.replace('_', ' ').split()\n",
    "    # Convert the first word to lowercase and capitalize the initials of the remaining words\n",
    "    camel_case_str = words[0].lower() + ''.join(word.capitalize() for word in words[1:])\n",
    "    return camel_case_str\n",
    "\n",
    "df.columns = [to_camel_case(col) for col in df.columns]\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3a5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0300fa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To prevent errors, converting 'Description','Invoice' and 'StockCode' to a string.\n",
    "# df['Description'] = df['Description'].astype(str)\n",
    "# df['Invoice'] = df['Invoice'].astype(str)\n",
    "# df['StockCode'] = df['StockCode'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e3fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160815cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.country.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda51f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_country=df[['country','customerId']]\n",
    "customer_country.groupby(['country'])['customerId'].aggregate('count').reset_index().sort_values('customerId', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955b32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4fc6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    # Checking if any value in the column is duplicated\n",
    "    has_duplicates = df[column].duplicated().any()\n",
    "    print(f'{column} has duplicates: {has_duplicates}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b7d73e",
   "metadata": {},
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df42018",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a2bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['description'].isnull()].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c90a0",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "- The Price in these rows is 0, indicating that these orders did not generate any purchases.\n",
    "\n",
    "- At present, we can impute it with 'UNKNOWN ITEM' and address those later during the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36665c2",
   "metadata": {},
   "source": [
    "## Features Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00809e78",
   "metadata": {},
   "source": [
    "#### Analyzing \"Description\" feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].value_counts().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e8df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd7c95",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "The code above shows that valid items are typically in uppercase, while non-valid or cancelled items are in lowercase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4715936",
   "metadata": {},
   "source": [
    "#### Analyzing Invoice feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba1e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invoice'].value_counts().tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e434bcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invoice'].value_counts().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08316253",
   "metadata": {},
   "source": [
    "# Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b64c01",
   "metadata": {},
   "source": [
    "## Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48619cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_country=df[['country','customerId','invoice']].drop_duplicates()\n",
    "customer_country.groupby(['country'])['customerId'].aggregate('count').reset_index().sort_values('customerId', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdaabaa",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "We will no longer track customers that appear to be duplicated, particularly when invoices for these customers are repeated in the same country."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d27c72",
   "metadata": {},
   "source": [
    "## Labelling Unknown Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].fillna('UNKNOWN ITEM')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70cca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['description'].fillna('UNKNOWN ITEM')\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb18c595",
   "metadata": {},
   "source": [
    "## Removing Unidentified Customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eab261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[pd.notnull(df['customerId'])]\n",
    "df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2bcfd7",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.scatter(x=df.index, y=df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76417f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1=df.quantile(.25)\n",
    "Q3=df.quantile(.75)\n",
    "IQR=Q3-Q1\n",
    "print(IQR)\n",
    "print(\"--------\")\n",
    "print(Q1)\n",
    "print(\"--------\")\n",
    "print(Q3)\n",
    "\n",
    "df=df[~((df<(Q1-1.5*IQR))|(df>(Q3+1.5*IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33862b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1_price = Q1['price'] \n",
    "\n",
    "# Filtering the dataset for products over 1.25 euros\n",
    "high_value_purchases = df[df['price'] > Q1_price]\n",
    "\n",
    "# Getting unique customers who have made high-value purchases\n",
    "unique_customers_high_value = high_value_purchases['customerId'].unique()\n",
    "\n",
    "# Getting the total number of unique customers in the entire dataset\n",
    "total_unique_customers = df['customerId'].unique()\n",
    "\n",
    "# Calculating the percentage of customers who have purchased items over 3000 euros\n",
    "percentage_high_value_customers = (len(unique_customers_high_value) / len(total_unique_customers)) * 100\n",
    "\n",
    "# Displaying the percentage\n",
    "print(f'Percentage of customers who have purchased items over 1.25 euros: {percentage_high_value_customers:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a683ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3_price = Q3['price'] \n",
    "\n",
    "# Filtering the dataset for products over 2.55 euros\n",
    "high_value_purchases = df[df['price'] > Q3_price]\n",
    "\n",
    "# Getting unique customers who have made high-value purchases\n",
    "unique_customers_high_value = high_value_purchases['customerId'].unique()\n",
    "\n",
    "# Getting the total number of unique customers in the entire dataset\n",
    "total_unique_customers = df['customerId'].unique()\n",
    "\n",
    "# Calculating the percentage of customers who have purchased items over 3000 euros\n",
    "percentage_high_value_customers = (len(unique_customers_high_value) / len(total_unique_customers)) * 100\n",
    "\n",
    "# Displaying the percentage\n",
    "print(f'Percentage of customers who have purchased items over 2.55 euros: {percentage_high_value_customers:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddce8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,6))\n",
    "plt.scatter(x=df.index, y=df['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b107bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62329b53",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "- To achieve a more precise clustering of products, we excluded products that cost over 7.5 € from our datasets. Our analysis aims to cluster regularly purchased products, and those over this price point are not considered in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976e6661",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf54644a",
   "metadata": {},
   "source": [
    "## Do we Have Returns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9da31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['quantity'] < 0].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3355a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['invoice'].isna().sum())\n",
    "#The code is not working unless we instruct .str.startswith() to consider NA/NaN values as False\n",
    "print(df[df['invoice'].str.startswith('C', na=False)].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec197741",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_invoices = df['invoice'].notna().sum()  # Count non-NA invoice entries\n",
    "invoices_starting_with_c = df['invoice'].str.startswith('C', na=False).sum()  # Count invoices starting with 'C'\n",
    "\n",
    "# Data for plotting\n",
    "sizes = [invoices_starting_with_c, total_invoices - invoices_starting_with_c]\n",
    "labels = ['Invoices Starting with C', 'Other Invoices']\n",
    "\n",
    "# Plotting the pie chart\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.title('Percentage of Invoices Returned')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ee9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoices_starting_with_c = df[df['invoice'].str.startswith('C', na=False)].shape[0]\n",
    "total_invoices = df['invoice'].notna().sum()\n",
    "percentage_starting_with_c = (invoices_starting_with_c / total_invoices) * 100\n",
    "print(\"Percentage of invoices starting with 'C': {:.2f}%\".format(percentage_starting_with_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef835fb9",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "Invoices beginning with the letter 'C' are designated as 'Canceling' or 'Returning' invoices.\n",
    "\n",
    "While a more in-depth analysis of these returns would be beneficial, for the sake of simplicity we will disregard them for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288e0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating total number of entries\n",
    "total_entries = len(df)\n",
    "\n",
    "# Counting number of entries where the invoice starts with 'C'\n",
    "invoices_starting_with_c = df['invoice'].str.startswith('C', na=False).sum()\n",
    "\n",
    "# Calculating the percentage\n",
    "percentage_starting_with_c = (invoices_starting_with_c / total_entries) * 100\n",
    "\n",
    "# Printing the result\n",
    "print(f\"Percentage of invoices starting with 'C': {percentage_starting_with_c:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3aa5995",
   "metadata": {},
   "source": [
    "## Removing Invoices Starting with 'C'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a334230",
   "metadata": {},
   "source": [
    "As the number of invoices starting with the letter 'C' represents only 1.90% of the total dataset and is not part of the purpose of the analysis, it was decided to remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6d7291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['invoice'].str.startswith('C', na=False)]\n",
    "\n",
    "# Now df does not contain rows where the invoice starts with 'C'\n",
    "print(\"Rows with invoices starting with 'C' have been removed.\")\n",
    "print(f\"Updated DataFrame shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc03df9c",
   "metadata": {},
   "source": [
    "## How Many Customers are Not Recurrent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1b009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_counts(df):\n",
    "   for i in df.columns:\n",
    "       count = df[i].nunique()\n",
    "       print(i, \": \", count)\n",
    "unique_counts(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637308f2",
   "metadata": {},
   "source": [
    "## What Items Were Purchased More Frequently?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1ba2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_counts = df['description'].value_counts().sort_values(ascending=False).iloc[0:15]\n",
    "plt.figure(figsize=(18,6))\n",
    "sns.barplot(x=item_counts.index, y=item_counts.values, palette=sns.cubehelix_palette(15))\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Which items were bought more often?\");\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90eb5abe",
   "metadata": {},
   "source": [
    "##  Which Invoices Had the Highest Number of Items?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f80b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_counts = df['invoice'].value_counts().sort_values(ascending=False).iloc[0:15]\n",
    "plt.figure(figsize=(18,6))\n",
    "sns.barplot(x=inv_counts.index, y=inv_counts.values, palette=sns.color_palette(\"BuGn_d\"))\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.title(\"Which invoices had the most items?\");\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a92b5",
   "metadata": {},
   "source": [
    "## What is the Country with The Highest Number of purchases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e9b372",
   "metadata": {},
   "outputs": [],
   "source": [
    "info = pd.DataFrame(data = df.groupby(['country'])['invoice'].nunique(), index=df.groupby(['country']).groups.keys()).T\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42af0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "plt.bar(list(df.groupby(['country']).groups.keys()), df.groupby(['country'])['customerId'].count())\n",
    "plt.xticks(rotation = 90, fontsize = 14)\n",
    "plt.title(\"Number of transanctions done for each country\")\n",
    "plt.ylabel(\"No. of trans.\")\n",
    "plt.xlabel(\"Country\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c4aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the number of unique invoices per country\n",
    "sales_per_country = df.groupby('country')['invoice'].nunique()\n",
    "\n",
    "# Calculating the total number of sales transactions\n",
    "total_sales = sales_per_country.sum()\n",
    "\n",
    "# Calculating the percentage of total sales for each country\n",
    "percent_sales = (sales_per_country / total_sales) * 100\n",
    "\n",
    "# Sorting the percentages to find the countries with the smallest percent of sales\n",
    "smallest_percent_sales = percent_sales.sort_values()\n",
    "\n",
    "# Displaying the sorted percentages\n",
    "print(smallest_percent_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362b03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering for countries with 1% or less in purchases\n",
    "countries_with_one_percent_or_less = percent_sales[percent_sales <= 1]\n",
    "\n",
    "# Counting the number of countries meeting the criterion\n",
    "number_of_countries = countries_with_one_percent_or_less.count()\n",
    "\n",
    "# Display the count\n",
    "print(f'Number of countries with 1% or less in purchases: {number_of_countries}')\n",
    "\n",
    "# Displaying the names of these countries\n",
    "print(\"Countries with 1% or less in purchases:\")\n",
    "print(countries_with_one_percent_or_less.index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6eb80f4",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "- The UK conducted the majority of the transactions, with a total of 19857.\n",
    "\n",
    "- 'Australia', 'Austria', 'Bahrain', 'Belgium', 'Brazil', 'Canada', 'Channel Islands', 'Cyprus', 'Denmark', 'Finland', 'Greece', 'Iceland', 'Israel', 'Italy', 'Japan', 'Korea', 'Lithuania', 'Malta', 'Netherlands', 'Nigeria', 'Norway', 'Poland', 'Portugal', 'RSA', 'Singapore', 'Spain', 'Sweden', 'Switzerland', 'Thailand', 'USA', 'United Arab Emirates', 'Unspecified', 'West Indies' are countries with less than the 1% of purchases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941fd94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df.groupby('invoice')[['quantity']].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3167e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.reset_index()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298295d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invoicedate'] = df.index\n",
    "\n",
    "# Merging df with df2 based on the invoice column using the 'left' join to retain all records from 'df' in the merged \n",
    "# DataFrame, while only the matching entries from 'df2' are included.\n",
    "\n",
    "df = df.merge(df2, how='left', on='invoice')\n",
    "\n",
    "# Changing the column names to clarify their meaning. 'quantity_x' has been replaced with 'product units' and 'quantityInv' with 'number of products invoiced in each invoice'.\n",
    "\n",
    "df = df.rename(columns={'quantity_x' : 'quantity', 'quantity_y' : 'quantityInv'})\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838c17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invoicedate'] = df['invoicedate'].dt.strftime('%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfd9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f82000",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8332bad",
   "metadata": {},
   "source": [
    "## What is The Revenue/Groth of The Company Thourgh the Year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bef56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['invoicedate'] = pd.to_datetime(df['invoicedate'])\n",
    "\n",
    "#creating YearMonth field for the ease of reporting and visualization\n",
    "df['invoiceyearmonth'] = df['invoicedate'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Calculate revenue for each row\n",
    "df['revenue'] = df['price'] * df['quantity']\n",
    "\n",
    "# Group by the new 'invoiceyearmonth' and sum the revenue\n",
    "df_revenue = df.groupby('invoiceyearmonth')['revenue'].sum().reset_index()\n",
    "\n",
    "# Calculating monthly percentage change\n",
    "df_revenue['monthlygrowth'] = df_revenue['revenue'].pct_change()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seting the figure size for better readability\n",
    "plt.figure(figsize=(12, 6))  \n",
    "plt.plot(df_revenue['invoiceyearmonth'], df_revenue['revenue'], marker='o')  # Plotting revenue over time\n",
    "# Adding a title\n",
    "plt.title('Monthly Revenue Over Time')  \n",
    "# Labeling the x-axis\n",
    "plt.xlabel('Year-Month') \n",
    "# Labeling the y-axis\n",
    "plt.ylabel('Revenue')  \n",
    "# Rotating date labels for better visibility\n",
    "plt.xticks(rotation=45)  \n",
    "# Adding a grid for easier reading\n",
    "plt.grid(True)  \n",
    "# Adjusting the layout to make room for the rotated date labels\n",
    "plt.tight_layout()  \n",
    "# Displaying the plot\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f54c6a",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "As can be seen over 2010, the company had a steady turnover until August, since then and until November it experienced an exponential turnover, finally in December the turnover dropped drastically. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f08cbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Plotting the monthly growth. Assuming the data goes up to November 2011 and excluding that from the plot.\n",
    "mask = df_revenue['invoiceyearmonth'] < '201112'\n",
    "plt.plot(df_revenue[mask]['invoiceyearmonth'], df_revenue[mask]['monthlygrowth'], marker='o', linestyle='-')\n",
    "\n",
    "# Adding title and labels\n",
    "plt.title('Monthly Growth Rate')\n",
    "plt.xlabel('Year-Month')\n",
    "plt.ylabel('Percentage Growth')\n",
    "\n",
    "# Rotate date labels for better readability\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf515a",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "As can be seen over the year as a whole, the company did not experience significant growth, although there was some growth in the first and last quarters of the year."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b1cbdd",
   "metadata": {},
   "source": [
    "# Clustering Analysis\n",
    "\n",
    "- Recency - Customers are clustered based on their most recent purchase.\n",
    "\n",
    "- Frequency - Customers are clustered based on their purchase frequency within the company.\n",
    "\n",
    "- Revenue - Customers are clustered based on benefits generated for the company through their purchases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0b42b8",
   "metadata": {},
   "source": [
    "## Customer Segmentation by Purchase Frequency and Revenue Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916102fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uk = df.query(\"country=='United Kingdom'\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1049d",
   "metadata": {},
   "source": [
    "Note\n",
    "\n",
    "To perform an analysis with less bias, the clustering analysis will solely focus on the United Kingdom, as it accounts for the majority of the company's purchases. This is due to the potential variation in customer behaviour between countries."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43a30ad",
   "metadata": {},
   "source": [
    "## Time Since Each Client's Largest Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed98f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#geting the max purchase date for each customer and create a dataframe with it\n",
    "df_uk_purchase = df_uk.groupby('customerId').invoicedate.max().reset_index()\n",
    "df_uk_purchase.columns = ['customerId','maxpurchasedate']\n",
    "\n",
    "#Taking observation points as the max invoice date in the dataset\n",
    "df_uk_purchase['recency'] = (df_uk_purchase['maxpurchasedate'].max() - df_uk_purchase['maxpurchasedate']).dt.days\n",
    "\n",
    "df_uk_purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61527a17",
   "metadata": {},
   "source": [
    "The analysis is determining the impact on revenue by considering the timing of customers' largest purchases in the past. It feature is being called 'recency'.\n",
    "\n",
    "- The dataset is grouping by 'customerid' and 'invoicedate' to track changes over time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce49d6",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e45f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a generic user dataframe to keep CustomerID and new segmentation scores\n",
    "df_user = pd.DataFrame(df_uk['customerId'].unique())\n",
    "df_user.columns = ['customerId']\n",
    "\n",
    "# Merging this dataframe to our new user dataframe\n",
    "df_user = pd.merge(df_user, df_uk_purchase[['customerId','recency']], on='customerId')\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "sse={}\n",
    "df_recency = df_user[['recency']]\n",
    "for k in range(1, 10):\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(df_recency)\n",
    "    df_recency[\"clusters\"] = kmeans.labels_\n",
    "    sse[k] = kmeans.inertia_ \n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8997a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#building 4 clusters for recency and add it to dataframe\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(df_user[['recency']])\n",
    "df_user['recencyCluster_Kmeans'] = kmeans.predict(df_user[['recency']])\n",
    "\n",
    "#function for ordering cluster numbers\n",
    "def order_cluster(cluster_field_name, target_field_name,df,ascending):\n",
    "    new_cluster_field_name = 'new_' + cluster_field_name\n",
    "    df_new = df.groupby(cluster_field_name)[target_field_name].mean().reset_index()\n",
    "    df_new = df_new.sort_values(by=target_field_name,ascending=ascending).reset_index(drop=True)\n",
    "    df_new['index'] = df_new.index\n",
    "    df_final = pd.merge(df,df_new[[cluster_field_name,'index']], on=cluster_field_name)\n",
    "    df_final = df_final.drop([cluster_field_name],axis=1)\n",
    "    df_final = df_final.rename(columns={\"index\":cluster_field_name})\n",
    "    return df_final\n",
    "\n",
    "df_user = order_cluster('recencyCluster_Kmeans', 'recency',df_user,False)\n",
    "\n",
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd333dc",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e4fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising an object neigh by calling a method NearestNeighbors()\n",
    "neigh = NearestNeighbors(n_neighbors = 20)\n",
    "\n",
    "# Training the model by calling a method fit()\n",
    "nbrs = neigh.fit(df_user[['customerId','recency']])\n",
    "\n",
    "# Storing the distance and indices into distances and indices arrays\n",
    "distances, indices = nbrs.kneighbors(df_user[['customerId','recency']])\n",
    "\n",
    "print(distances, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34fa4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting K-distance Graph\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(distances)\n",
    "plt.title('K-distance Graph',fontsize=20)\n",
    "plt.xlabel('Data Points sorted by distance',fontsize=14)\n",
    "plt.ylabel('Epsilon',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b68f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise an object by calling a method DBSCAN along with parameters as eps and min_samples\n",
    "dbscan_opt = DBSCAN(eps = 50, min_samples =6)\n",
    "\n",
    "# Train the model by calling a method fit()\n",
    "dbscan_opt.fit(df_user[['customerId','recency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69def9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another column into the dataframe (df)\n",
    "df_user['recencyCluster_DBSCAN'] = dbscan_opt.labels_\n",
    "\n",
    "# Display the counts by labels\n",
    "df_user['recencyCluster_DBSCAN'].value_counts()\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b9105",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dbscan_opt.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['recencyCluster_DBSCAN']=dbscan_opt.labels_\n",
    "df_user['recencyCluster_DBSCAN'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e6f35d",
   "metadata": {},
   "source": [
    "## Frequency Each Client Purchase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94780acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting order counts for each user and create a dataframe with it\n",
    "df_frequency = df_uk.groupby('customerId').invoicedate.count().reset_index()\n",
    "df_frequency.columns = ['customerId','frequency']\n",
    "\n",
    "#adding this data to our main dataframe\n",
    "df_user = pd.merge(df_user, df_frequency, on='customerId')\n",
    "\n",
    "df_user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896992a7",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70dc6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(df_user[['frequency']])\n",
    "df_user['frequencyCluster_Kmeans'] = kmeans.predict(df_user[['frequency']])\n",
    "\n",
    "# ordering the frequency cluster\n",
    "df_user = order_cluster('frequencyCluster_Kmeans', 'frequency',df_user,True)\n",
    "\n",
    "# details of each cluster\n",
    "df_user.groupby('frequencyCluster_Kmeans')['frequency'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856dd86b",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569d0b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising an object neigh by calling a method NearestNeighbors()\n",
    "neigh = NearestNeighbors(n_neighbors = 20)\n",
    "\n",
    "# Training the model by calling a method fit()\n",
    "nbrs = neigh.fit(df_user[['customerId','frequency']])\n",
    "\n",
    "# Storing the distance and indices into distances and indices arrays\n",
    "distances, indices = nbrs.kneighbors(df_user[['customerId','frequency']])\n",
    "\n",
    "print(distances, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f157bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting K-distance Graph\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(distances)\n",
    "plt.title('K-distance Graph',fontsize=20)\n",
    "plt.xlabel('Data Points sorted by distance',fontsize=14)\n",
    "plt.ylabel('Epsilon',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917d5417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise an object by calling a method DBSCAN along with parameters as eps and min_samples\n",
    "dbscan_opt = DBSCAN(eps = 100, min_samples =6)\n",
    "\n",
    "# Train the model by calling a method fit()\n",
    "dbscan_opt.fit(df_user[['customerId','frequency']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another column into the dataframe (df)\n",
    "df_user['frequencyCluster_DBSCAN'] = dbscan_opt.labels_\n",
    "\n",
    "# Display the counts by labels\n",
    "df_user['frequencyCluster_DBSCAN'].value_counts()\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8d68aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dbscan_opt.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf3757",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['frequencyCluster_DBSCAN']=dbscan_opt.labels_\n",
    "df_user['frequencyCluster_DBSCAN'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6524985b",
   "metadata": {},
   "source": [
    "## Revenue the company makes by product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd1c716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating revenue for each customer\n",
    "df_user['revenue'] = df['price'] * df['quantityInv']\n",
    "df_revenue = df_user.groupby('customerId').revenue.sum().reset_index()\n",
    "\n",
    "#merging it with our main dataframe\n",
    "df_user = pd.merge(df_user, df_revenue, on='customerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b7042",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399bdbc7",
   "metadata": {},
   "source": [
    "## K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1a0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying clustering\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(df_user[['revenue_x']])\n",
    "df_user['revenueCluster_Kmeans'] = kmeans.predict(df_user[['revenue_x']])\n",
    "\n",
    "\n",
    "#ordering the cluster numbers\n",
    "df_user = order_cluster('revenueCluster_Kmeans', 'revenue_x',df_user,True)\n",
    "\n",
    "#showing details of the dataframe\n",
    "df_user.groupby('revenueCluster_Kmeans')['revenue_x'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8b618",
   "metadata": {},
   "source": [
    "## DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187dad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising an object neigh by calling a method NearestNeighbors()\n",
    "neigh = NearestNeighbors(n_neighbors = 20)\n",
    "\n",
    "# Training the model by calling a method fit()\n",
    "nbrs = neigh.fit(df_user[['customerId','revenue_x']])\n",
    "\n",
    "# Storing the distance and indices into distances and indices arrays\n",
    "distances, indices = nbrs.kneighbors(df_user[['customerId','revenue_x']])\n",
    "\n",
    "print(distances, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc7d3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting K-distance Graph\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(distances)\n",
    "plt.title('K-distance Graph',fontsize=20)\n",
    "plt.xlabel('Data Points sorted by distance',fontsize=14)\n",
    "plt.ylabel('Epsilon',fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7474c45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise an object by calling a method DBSCAN along with parameters as eps and min_samples\n",
    "dbscan_opt = DBSCAN(eps = 100, min_samples =6)\n",
    "\n",
    "# Train the model by calling a method fit()\n",
    "dbscan_opt.fit(df_user[['customerId','revenue_x']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c9a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add another column into the dataframe (df)\n",
    "df_user['revenueCluster_DBSCAN'] = dbscan_opt.labels_\n",
    "\n",
    "# Display the counts by labels\n",
    "df_user['revenueCluster_DBSCAN'].value_counts()\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordering the cluster numbers\n",
    "df_user = order_cluster('revenueCluster_DBSCAN', 'revenue_x',df_user,True)\n",
    "\n",
    "#showing details of the dataframe\n",
    "df_user.groupby('revenueCluster_DBSCAN')['revenue_x'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9d3269",
   "metadata": {},
   "outputs": [],
   "source": [
    "max(dbscan_opt.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd6cc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user['revenueCluster_DBSCAN']=dbscan_opt.labels_\n",
    "df_user['revenueCluster_DBSCAN'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aceb28b4",
   "metadata": {},
   "source": [
    "## Overall Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ea6a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f2a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_user.to_csv('df_user.csv', index=False)\n",
    "\n",
    "# # If you need to provide a download link in Jupyter Notebook:\n",
    "# from IPython.display import FileLink\n",
    "# FileLink(r'df_user.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df3cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating overallScore by summing the cluster scores\n",
    "df_user['overallScore'] = (df_user['recencyCluster_Kmeans'] +\n",
    "                           df_user['frequencyCluster_Kmeans'] +\n",
    "                           df_user['revenueCluster_Kmeans'] +\n",
    "                           df_user['recencyCluster_DBSCAN'] +\n",
    "                           df_user['frequencyCluster_DBSCAN'] +\n",
    "                           df_user['revenueCluster_DBSCAN'])\n",
    "\n",
    "# Grouping by overallScore and calculate mean of 'recency', 'frequency', and 'revenue'\n",
    "df_user.groupby('overallScore')[['recency', 'frequency', 'revenue_x']].mean()  # Assuming revenue_x is the correct revenue column to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63488698",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_user.describe())\n",
    "\n",
    "df_user.loc[df_user['overallScore']<=5,'Segment'] = 'Low-Value'\n",
    "df_user.loc[df_user['overallScore']>5,'Segment'] = 'Mid-Value' \n",
    "df_user.loc[df_user['overallScore']>7,'Segment'] = 'High-Value' \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57585ad6",
   "metadata": {},
   "source": [
    "## Clustering Revenue vs Frequency - K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e203b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_cluster = df_user[['revenue_x', 'frequency']]\n",
    "\n",
    "# Applying K-means clustering on the full dataset with an optimal cluster count\n",
    "km = KMeans(n_clusters=4, random_state=42)\n",
    "data_to_cluster['cluster'] = km.fit_predict(data_to_cluster)\n",
    "\n",
    "# Defining cluster names based on the discussed characteristics\n",
    "cluster_labels = {0: \"Casual\", 1: \"VIPs\", 2: \"Regulars\", 3: \"Big Spenders\"}\n",
    "data_to_cluster['cluster_label'] = data_to_cluster['cluster'].map(cluster_labels)\n",
    "\n",
    "# Plotting Revenue vs Frequency with cluster coloring and labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(data_to_cluster['revenue_x'], data_to_cluster['frequency'], \n",
    "                      c=data_to_cluster['cluster'], cmap='viridis', alpha=0.5)\n",
    "plt.title('Revenue vs Frequency - K-means Clustering')\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "# Creating a legend with the named clusters\n",
    "legend_labels = [cluster_labels[i] for i in range(4)]  # List of labels for the legend\n",
    "legend_handles = scatter.legend_elements()[0]  # Get legend handles\n",
    "legend1 = plt.legend(legend_handles, legend_labels, title=\"Clusters\")\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931f678c",
   "metadata": {},
   "source": [
    "## Clustering Revenue vs Frequency - DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c240cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_cluster = df_user[['revenue_x', 'frequency']]\n",
    "data_to_cluster['cluster'] = df_user['revenueCluster_DBSCAN']\n",
    "\n",
    "# Defining custom labels for DBSCAN clusters based on the hypothetical understanding of the cluster\n",
    "# Adjusting these keys based on the actual cluster numbers observed\n",
    "cluster_labels = {\n",
    "    -1: \"Outliers\",  # DBSCAN labels noise as -1\n",
    "    0: \"Sporadic Shoppers\",\n",
    "    1: \"Occasional Shoppers\",\n",
    "    2: \"Frequent Customers\",\n",
    "    3: \"Regular Customers\",\n",
    "    4: \"Consistent Customers\",\n",
    "    5: \"Loyal Customers\",\n",
    "    6: \"Very Loyal Customers\",\n",
    "    7: \"Premium Customers\",\n",
    "    8: \"Very Premium Customers\"\n",
    "}\n",
    "data_to_cluster['cluster_label'] = data_to_cluster['cluster'].map(cluster_labels)\n",
    "\n",
    "# Plotting Revenue vs Frequency with DBSCAN cluster coloring\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(data_to_cluster['revenue_x'], data_to_cluster['frequency'], \n",
    "                      c=data_to_cluster['cluster'], cmap='Set1', alpha=0.5)\n",
    "plt.title('Revenue vs Frequency - DBSCAN Clustering')\n",
    "plt.xlabel('Revenue')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "# Creating a legend with the named clusters\n",
    "legend_labels = [cluster_labels.get(i, \"Unknown\") for i in sorted(data_to_cluster['cluster'].unique())]\n",
    "legend_handles = scatter.legend_elements()[0]  # Get legend handles\n",
    "legend1 = plt.legend(legend_handles, legend_labels, title=\"Clusters\")\n",
    "plt.gca().add_artist(legend1)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f714f60e",
   "metadata": {},
   "source": [
    "## Clustering Revenue vs Recency - K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639199db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_descriptive_mapping = {\n",
    "    1: \"Frequent & High Spenders\",\n",
    "    2: \"Recent & Moderate Spenders\",\n",
    "    3: \"Inactive & High Spenders\",\n",
    "    4: \"Inactive & Low Spenders\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to the DataFrame\n",
    "df_user['descriptive_cluster'] = df_user['recencyCluster_Kmeans'].map(cluster_descriptive_mapping)\n",
    "\n",
    "# Setting up the plot with the new descriptive labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_user, x='recency', y='revenue_x', hue='descriptive_cluster', palette='viridis', s=100, alpha=0.7)\n",
    "\n",
    "# Enhancing the plot\n",
    "plt.title('Revenue vs Recency', fontsize=16)\n",
    "plt.xlabel('Recency (days since last purchase)', fontsize=14)\n",
    "plt.ylabel('Revenue', fontsize=14)\n",
    "plt.legend(title='Customer Segment', title_fontsize='13', fontsize='12', loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75fc2cf",
   "metadata": {},
   "source": [
    "## Clustering Revenue vs Recency - DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb572ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Assign more descriptive labels based on cluster IDs and characteristics\n",
    "descriptive_labels = {\n",
    "    -1: 'Noise - Outliers',\n",
    "    0: 'Inactive & Spender',\n",
    "    1: 'Inactive & Good Spender',\n",
    "    2: 'Recent & Moderate Spender',\n",
    "    3: 'Recent & Good Spender',\n",
    "    4: 'Recent & High Spender',\n",
    "    5: 'Frequent & Good Spender',\n",
    "    6: 'Frequent & High Spender'\n",
    "}\n",
    "\n",
    "# Create a scatter plot with uniform circle markers\n",
    "for cluster_id in sorted(df_user['recencyCluster_DBSCAN'].unique()):\n",
    "    cluster_data = df_user[df_user['recencyCluster_DBSCAN'] == cluster_id]\n",
    "    label = descriptive_labels.get(cluster_id, f'Cluster {cluster_id}')\n",
    "    plt.scatter(cluster_data['recency'], cluster_data['revenue_x'], label=label, marker='o', s=100)\n",
    "\n",
    "# Enhancing the plot\n",
    "plt.title('Refined Revenue vs Recency (DBSCAN Clustering)', fontsize=16)\n",
    "plt.xlabel('Recency (days since last purchase)', fontsize=14)\n",
    "plt.ylabel('Revenue', fontsize=14)\n",
    "plt.legend(title='DBSCAN Cluster', title_fontsize='13', fontsize='12', loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the refined plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9748bbc",
   "metadata": {},
   "source": [
    "## Clustering Revenue vs Frecency - K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5021fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_cluster_descriptive_mapping = {\n",
    "    0: \"Low Activity\",\n",
    "    1: \"Moderate Activity\",\n",
    "    2: \"High Activity\",\n",
    "    3: \"Very High Activity\"\n",
    "}\n",
    "\n",
    "# Apply the mapping to the DataFrame\n",
    "df_user['descriptive_frequency_label'] = df_user['frequencyCluster_Kmeans'].map(frequency_cluster_descriptive_mapping)\n",
    "\n",
    "\n",
    "# Setting up the plot with uniform circle markers and an easier to distinguish color palette\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_user, x='frequency', y='revenue_x', hue='descriptive_frequency_label', \n",
    "                palette='Set2', s=100, style='descriptive_frequency_label', markers=['o']*4, alpha=0.7)\n",
    "\n",
    "# Enhancing the plot\n",
    "plt.title('Revenue vs Frequency with Accessible Colors', fontsize=16)\n",
    "plt.xlabel('Frequency (number of transactions)', fontsize=14)\n",
    "plt.ylabel('Revenue', fontsize=14)\n",
    "plt.legend(title='Customer Activity Level', title_fontsize='13', fontsize='12', loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85a829b",
   "metadata": {},
   "source": [
    "## Clustering Revenue vs Frecency - DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c804da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign more descriptive labels based on DBSCAN clustering characteristics\n",
    "dbscan_frequency_descriptive_labels = {\n",
    "    -1: 'Outliers - Noise',\n",
    "    0: 'Low Activity',\n",
    "    1: 'Moderate Activity',\n",
    "    2: 'High Activity',\n",
    "    3: 'Very High Activity'\n",
    "}\n",
    "\n",
    "# Map the new descriptive labels to the data\n",
    "df_user['descriptive_frequency_dbscan_label'] = df_user['frequencyCluster_DBSCAN'].map(dbscan_frequency_descriptive_labels)\n",
    "\n",
    "# Setting up the plot with descriptive labels\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_user, x='frequency', y='revenue_x', hue='descriptive_frequency_dbscan_label', \n",
    "                palette='Set2', s=100, marker='o', alpha=0.7)\n",
    "\n",
    "# Enhancing the plot\n",
    "plt.title('Revenue vs Frequency with Descriptive DBSCAN Labels', fontsize=16)\n",
    "plt.xlabel('Frequency (number of transactions)', fontsize=14)\n",
    "plt.ylabel('Revenue', fontsize=14)\n",
    "plt.legend(title='DBSCAN Frequency Cluster', title_fontsize='13', fontsize='12', loc='upper right')\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the updated plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8154c63",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c595dc4",
   "metadata": {},
   "source": [
    "Scikit-learn.org. (2017). sklearn.cluster.DBSCAN — scikit-learn 0.22 documentation. [online] Available at: https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e48bc9b",
   "metadata": {},
   "source": [
    "Sharma, A. (2020). How Does DBSCAN Clustering Work? | DBSCAN Clustering for ML. [online] Analytics Vidhya. Available at: https://www.analyticsvidhya.com/blog/2020/09/how-dbscan-clustering-works/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d3daaa",
   "metadata": {},
   "source": [
    "GeeksforGeeks. (2010). Print nodes at k distance from root. [online] Available at: https://www.geeksforgeeks.org/print-nodes-at-k-distance-from-root/ [Accessed 10 Apr. 2024]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
